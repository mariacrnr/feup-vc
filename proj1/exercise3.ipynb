{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Read images and initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_WIDTH = 0\n",
    "MAX_WIDTH = 500\n",
    "MIN_HEIGHT = 0\n",
    "MAX_HEIGHT = 500\n",
    "ACCEPTANCE_THRESHOLD = 0.7\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# simplesPic + simple1 & simple2 is another valid case\n",
    "\n",
    "img = cv2.imread(\"./images/markers.png\") # use aruco.jpg for more complex calculation\n",
    "\n",
    "template1 = cv2.imread('./images/template1.png') \n",
    "template2 = cv2.imread('./images/template2.png')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define Template Matching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def templateMatch(img, warped_img, template, homography, color):\n",
    "    # Rescale template to match the image size\n",
    "    template = cv2.resize(template, (MAX_WIDTH - MIN_WIDTH, MAX_HEIGHT - MIN_HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    img_gray = cv2.cvtColor(warped_img, cv2.COLOR_BGR2GRAY)\n",
    "    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    res = cv2.matchTemplate(img_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    # if below the threshold, discard, else continue\n",
    "    if res[0][0] < 0.8: \n",
    "        return\n",
    "    else:\n",
    "        print(\"Template matched with a value of:\", res[0][0])\n",
    "    \n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    h, w = template_gray.shape[:2]\n",
    "    top_left = max_loc\n",
    "    top_right = (top_left[0] + w, top_left[1])\n",
    "    bottom_left = (top_left[0], top_left[1] + h)\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "    # retransform homography transformed coordinates to the original image values\n",
    "    og_pts = cv2.perspectiveTransform(np.array([[[top_left, top_right, bottom_left, bottom_right]]], dtype=np.float32).reshape(-1, 4, 2), np.linalg.inv(homography))[0]\n",
    "    top_left_og = (int(og_pts[0][0]), int(og_pts[0][1]))\n",
    "    top_right_og = (int(og_pts[1][0]), int(og_pts[1][1]))\n",
    "    bottom_left_og = (int(og_pts[2][0]), int(og_pts[2][1]))\n",
    "    bottom_right_og = (int(og_pts[3][0]), int(og_pts[3][1]))\n",
    "\n",
    "    # draw marker borders\n",
    "    cv2.line(img,top_left_og,top_right_og,color,2)\n",
    "    cv2.line(img,top_right_og,bottom_right_og,color,2)\n",
    "    cv2.line(img,bottom_right_og,bottom_left_og,color,2)\n",
    "    cv2.line(img,bottom_left_og,top_left_og,color,2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Define vector similarity comparison function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to skip iterations and acelerate the matching process\n",
    "\n",
    "def vector_similarity(v1, v2):\n",
    "    v1 = [v1[0][0], v1[0][1]]\n",
    "    v2 = [v2[0][0], v2[0][1]]\n",
    "\n",
    "    vectorial_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "\n",
    "    size_similarity = norm_v1 / norm_v2\n",
    "    if (size_similarity < 0.95 or size_similarity > 1.05): # size acceptance threshold\n",
    "        return False\n",
    "\n",
    "    cosine = vectorial_product / (norm_v1 * norm_v2)\n",
    "    if (cosine < 0.98): # 11deg acceptance threshold\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5A: Regular Corner Detection(Harris & Shi-Tomasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = np.float32(gray)\n",
    "\n",
    "# maxCorners: more than 50 corners will take more than 12 minutes. Limit to preserve time usage.\n",
    "# qualityLevel: 0.01 minimum. Corner acceptance ratio considering quality. Increasing the value would skip important corners\n",
    "# minDistance: avoid corners being marked in the same spot(a few pixels to the side)\n",
    "# blockSize: corner pixel block considered group size\n",
    "# useHarrisDetector: True to Harris, False to Shi-Tomasi\n",
    "corners = cv2.goodFeaturesToTrack(gray, maxCorners = 50, qualityLevel = 0.05, minDistance = 10, blockSize = 2, useHarrisDetector = True)\n",
    "corners = np.int0(corners)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5B: Contour based Corner Detection(Faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = []\n",
    "\n",
    "# Binary inv to catch template borders\n",
    "_,  thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "# Find the contours in the thresholded image\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate through each contour and if it is a 4 sided polygon, add corners\n",
    "for border in contours:\n",
    "    # Approximates a polygonal curve. Goal is to find 4 sided polygon.\n",
    "    approx = cv2.approxPolyDP(border, 0.01*cv2.arcLength(border, True), True)\n",
    "    if len(approx) == 4:\n",
    "        for c in approx:\n",
    "            corners.append(c)\n",
    "\n",
    "# Convert list into no array type\n",
    "corners = np.array(corners)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Paint detected corners in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of corners:\", len(corners))\n",
    "\n",
    "for c in range(0, len(corners)):\n",
    "    x = corners[c][0][0]\n",
    "    y = corners[c][0][1]\n",
    "    for i in range(-1, 2, 1):\n",
    "        for j in range(-1, 2, 1):\n",
    "            img[y + i][x + j] = (255, 0 , 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Iterate through all the corners and try to find a match with the templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible permutations of 4 corners\n",
    "corner_permutations = itertools.permutations(range(len(corners)), 4)\n",
    "\n",
    "count = 0\n",
    "# Iterate over all the corner permutations\n",
    "for indexes in corner_permutations:\n",
    "    # Calculation status information. Prints every 100 iterations\n",
    "    count += 1\n",
    "    if (count % 10000) == 0:\n",
    "        ts = time.time() - t0\n",
    "        print(\"Count:\", count, \"Elapsed time:\", ts)\n",
    "\n",
    "    # Extract the x, y positions of the corners\n",
    "    pts = corners[list(indexes)]   \n",
    "    # Create 2 vectors from the 4 points to evaluate parallelism(Necessary to be a square)  \n",
    "    v1 = pts[1] - pts[0]\n",
    "    v2 = pts[2] - pts[3]\n",
    "    # If not, discard\n",
    "    if (not vector_similarity(v1, v2)):\n",
    "        continue\n",
    "\n",
    "    # Homography calculation and image transformation to match template. Evaluate similarity. If it matches paint the borders in red for 1st and green for 2nd\n",
    "    homography, _ = cv2.findHomography(pts, np.array([[MIN_WIDTH, MIN_HEIGHT], [MIN_WIDTH, MAX_HEIGHT], [MAX_WIDTH, MAX_HEIGHT], [MAX_WIDTH, MIN_HEIGHT]], dtype=np.float32))\n",
    "    warped_img = cv2.warpPerspective(img, homography, (MAX_WIDTH - MIN_WIDTH, MAX_HEIGHT - MIN_HEIGHT))\n",
    "    templateMatch(img, warped_img, template1, homography, (0, 0, 255))\n",
    "    templateMatch(img, warped_img, template2, homography, (0, 255, 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the result\n",
    "cv2.imshow(\"Result\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
